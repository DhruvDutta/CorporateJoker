{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691ce255-c89d-4822-8281-be6b0dfa7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "fbrom keras.preprocessing.sequence import pad_sequences\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36873136-b6fc-497a-8ba2-f2fa9d6676c1",
   "metadata": {},
   "source": [
    "## Reading data and removing unnecessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19e1f10-b0b2-4fdc-b67b-14afdb0be7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Did you hear about the Native American man tha...</td>\n",
       "      <td>He nearly drown in his own tea pee.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What's the best anti diarrheal prescription?</td>\n",
       "      <td>Mycheexarphlexin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>What do you call a person who is outside a doo...</td>\n",
       "      <td>Matt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Which Star Trek character is a member of the m...</td>\n",
       "      <td>Jean-Luc Pickacard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What's the difference between a bullet and a h...</td>\n",
       "      <td>A bullet doesn't miss Harambe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           Question  \\\n",
       "0   1  Did you hear about the Native American man tha...   \n",
       "1   2       What's the best anti diarrheal prescription?   \n",
       "2   3  What do you call a person who is outside a doo...   \n",
       "3   4  Which Star Trek character is a member of the m...   \n",
       "4   5  What's the difference between a bullet and a h...   \n",
       "\n",
       "                                Answer  \n",
       "0  He nearly drown in his own tea pee.  \n",
       "1                     Mycheexarphlexin  \n",
       "2                                 Matt  \n",
       "3                   Jean-Luc Pickacard  \n",
       "4        A bullet doesn't miss Harambe  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('jokes.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff010e2-de21-4957-802c-386db1e1be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['ID'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7964396-0cb5-4f83-a87f-35e859adaf45",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc7ac4ff-c61f-47c1-828e-8c5c28035fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower() #convert all the chracters into small letters\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}'+=|.!?,]\", \"\", text)\n",
    "    text = text.replace(\"[\", \"\")\n",
    "    text = text.replace(\"]\", \"\")\n",
    "    return clean(text,no_emoji=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c661ea-211d-477a-aaf5-b27d228a357a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>cleaned_Q</th>\n",
       "      <th>cleaned_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did you hear about the Native American man tha...</td>\n",
       "      <td>He nearly drown in his own tea pee.</td>\n",
       "      <td>[did, you, hear, about, the, native, american,...</td>\n",
       "      <td>[he, nearly, drown, in, his, own, tea, pee]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's the best anti diarrheal prescription?</td>\n",
       "      <td>Mycheexarphlexin</td>\n",
       "      <td>[what, is, the, best, anti, diarrheal, prescri...</td>\n",
       "      <td>[mycheexarphlexin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a person who is outside a doo...</td>\n",
       "      <td>Matt</td>\n",
       "      <td>[what, do, you, call, a, person, who, is, outs...</td>\n",
       "      <td>[matt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which Star Trek character is a member of the m...</td>\n",
       "      <td>Jean-Luc Pickacard</td>\n",
       "      <td>[which, star, trek, character, is, a, member, ...</td>\n",
       "      <td>[jeanluc, pickacard]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's the difference between a bullet and a h...</td>\n",
       "      <td>A bullet doesn't miss Harambe</td>\n",
       "      <td>[what, is, the, difference, between, a, bullet...</td>\n",
       "      <td>[a, bullet, does, not, miss, harambe]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Did you hear about the Native American man tha...   \n",
       "1       What's the best anti diarrheal prescription?   \n",
       "2  What do you call a person who is outside a doo...   \n",
       "3  Which Star Trek character is a member of the m...   \n",
       "4  What's the difference between a bullet and a h...   \n",
       "\n",
       "                                Answer  \\\n",
       "0  He nearly drown in his own tea pee.   \n",
       "1                     Mycheexarphlexin   \n",
       "2                                 Matt   \n",
       "3                   Jean-Luc Pickacard   \n",
       "4        A bullet doesn't miss Harambe   \n",
       "\n",
       "                                           cleaned_Q  \\\n",
       "0  [did, you, hear, about, the, native, american,...   \n",
       "1  [what, is, the, best, anti, diarrheal, prescri...   \n",
       "2  [what, do, you, call, a, person, who, is, outs...   \n",
       "3  [which, star, trek, character, is, a, member, ...   \n",
       "4  [what, is, the, difference, between, a, bullet...   \n",
       "\n",
       "                                     cleaned_A  \n",
       "0  [he, nearly, drown, in, his, own, tea, pee]  \n",
       "1                           [mycheexarphlexin]  \n",
       "2                                       [matt]  \n",
       "3                         [jeanluc, pickacard]  \n",
       "4        [a, bullet, does, not, miss, harambe]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import RegexpTokenizer\n",
    "tokaniser=RegexpTokenizer(r\"\\w+\")\n",
    "df['cleaned_Q'] = [tokaniser.tokenize(clean_text(sentence)) for sentence in df['Question']]\n",
    "df['cleaned_A'] = [tokaniser.tokenize(clean_text(sentence)) for sentence in df['Answer']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0967ce1-6539-4c7b-bda1-c4c8eb8138a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38269"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e13e08-9a74-4c01-9635-75de264f2019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['cleaned_A'].str.len() < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b23539d-326f-40f1-99a4-e4dc758ca73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_Q'] =df[['cleaned_Q']].apply(lambda words:[\" \".join(word) for word in words]).to_numpy()\n",
    "df['cleaned_A'] =df[['cleaned_A']].apply(lambda words:[\" \".join(word) for word in words]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9389b2c5-e03a-4e54-bc71-bf96f32cc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_val = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51f4a788-1523-400d-9330-95401fa60f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 7166\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([str(i) for i in df['cleaned_Q'].sample(n=range_val,random_state=121)] +  [str(i) for i in df['cleaned_A'].sample(n=range_val,random_state=121)])\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22a13ad-7908-4702-aaac-7690ed71cdda",
   "metadata": {},
   "source": [
    "## Converting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54190c25-7388-4ad2-9603-b6595eb53d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 21) 21\n",
      "(3000, 19) 19\n",
      "(3000, 19, 7166)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "\n",
    "vocab = []\n",
    "for word in tokenizer.word_index:\n",
    "    vocab.append( word )\n",
    "\n",
    "def tokenize( sentences ):\n",
    "    tokens_list = []\n",
    "    vocabulary = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub( '[^a-zA-Z]', ' ', sentence )\n",
    "        tokens = sentence.split()\n",
    "        vocabulary += tokens\n",
    "        tokens_list.append( tokens )\n",
    "    return tokens_list , vocabulary\n",
    "\n",
    "\n",
    "# encoder_input_data\n",
    "tokenized_questions = tokenizer.texts_to_sequences( [str(i) for i in df['cleaned_Q'].sample(n=range_val,random_state=121)] )\n",
    "maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n",
    "padded_questions = tf.keras.preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen_questions , padding='post' )\n",
    "encoder_input_data = np.array( padded_questions )\n",
    "print( encoder_input_data.shape , maxlen_questions )\n",
    "\n",
    "# decoder_input_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( [str(i) for i in df['cleaned_A'].sample(n=range_val,random_state=121)] )\n",
    "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
    "padded_answers = tf.keras.preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "decoder_input_data = np.array( padded_answers )\n",
    "print( decoder_input_data.shape , maxlen_answers )\n",
    "\n",
    "# decoder_output_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences( [str(i) for i in df['cleaned_A'].sample(n=range_val,random_state=121)] )\n",
    "for i in range(len(tokenized_answers)) :\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "padded_answers = tf.keras.preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "onehot_answers = tf.keras.utils.to_categorical( padded_answers,VOCAB_SIZE)\n",
    "decoder_output_data = np.array( onehot_answers)\n",
    "print( decoder_output_data.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcc8d8ae-9f47-407b-b119-35b3d48539c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True ,dropout=0.33)( encoder_embedding)\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 100 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True ,dropout=0.33)\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c2b48f6-5be7-4fd4-b26a-5bdee57a38f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed68f6f4-c110-4c15-897d-35396fbb7caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopper=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto',restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49212e20-697e-40b6-970f-2af41d7a926e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 21)]         0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 19)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 21, 200)      1433200     ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 19, 100)      716600      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  [(None, 200),        320800      ['embedding_4[0][0]']            \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  [(None, 19, 200),    240800      ['embedding_5[0][0]',            \n",
      "                                 (None, 200),                     'lstm_4[0][1]',                 \n",
      "                                 (None, 200)]                     'lstm_4[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 19, 7166)     1440366     ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,151,766\n",
      "Trainable params: 4,151,766\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "812aba1f-bf95-47c6-9384-d569be7a4eb0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "75/75 - 14s - loss: 2.0194 - accuracy: 0.1791 - val_loss: 1.7603 - val_accuracy: 0.1899 - 14s/epoch - 180ms/step\n",
      "Epoch 2/150\n",
      "75/75 - 3s - loss: 1.7080 - accuracy: 0.1834 - val_loss: 1.7431 - val_accuracy: 0.1899 - 3s/epoch - 45ms/step\n",
      "Epoch 3/150\n",
      "75/75 - 3s - loss: 1.6499 - accuracy: 0.1834 - val_loss: 1.7648 - val_accuracy: 0.1899 - 3s/epoch - 46ms/step\n",
      "Epoch 4/150\n",
      "75/75 - 4s - loss: 1.6150 - accuracy: 0.1828 - val_loss: 1.7747 - val_accuracy: 0.1892 - 4s/epoch - 51ms/step\n",
      "Epoch 5/150\n",
      "75/75 - 4s - loss: 1.5753 - accuracy: 0.1859 - val_loss: 1.7963 - val_accuracy: 0.1933 - 4s/epoch - 53ms/step\n",
      "Epoch 6/150\n",
      "75/75 - 5s - loss: 1.5375 - accuracy: 0.1972 - val_loss: 1.8052 - val_accuracy: 0.1924 - 5s/epoch - 61ms/step\n",
      "Epoch 7/150\n",
      "75/75 - 4s - loss: 1.5049 - accuracy: 0.2034 - val_loss: 1.8221 - val_accuracy: 0.1965 - 4s/epoch - 56ms/step\n",
      "Epoch 8/150\n",
      "75/75 - 4s - loss: 1.4714 - accuracy: 0.2147 - val_loss: 1.8216 - val_accuracy: 0.2019 - 4s/epoch - 59ms/step\n",
      "Epoch 9/150\n",
      "75/75 - 4s - loss: 1.4391 - accuracy: 0.2218 - val_loss: 1.8369 - val_accuracy: 0.2013 - 4s/epoch - 55ms/step\n",
      "Epoch 10/150\n",
      "75/75 - 5s - loss: 1.4068 - accuracy: 0.2276 - val_loss: 1.8290 - val_accuracy: 0.2060 - 5s/epoch - 65ms/step\n",
      "Epoch 11/150\n",
      "75/75 - 4s - loss: 1.3753 - accuracy: 0.2354 - val_loss: 1.8315 - val_accuracy: 0.2010 - 4s/epoch - 53ms/step\n",
      "Epoch 12/150\n",
      "75/75 - 4s - loss: 1.3425 - accuracy: 0.2435 - val_loss: 1.8518 - val_accuracy: 0.2003 - 4s/epoch - 56ms/step\n",
      "Epoch 13/150\n",
      "75/75 - 4s - loss: 1.3119 - accuracy: 0.2498 - val_loss: 1.8442 - val_accuracy: 0.2076 - 4s/epoch - 56ms/step\n",
      "Epoch 14/150\n",
      "75/75 - 4s - loss: 1.2808 - accuracy: 0.2563 - val_loss: 1.8561 - val_accuracy: 0.1968 - 4s/epoch - 59ms/step\n",
      "Epoch 15/150\n",
      "75/75 - 5s - loss: 1.2501 - accuracy: 0.2624 - val_loss: 1.8685 - val_accuracy: 0.1946 - 5s/epoch - 64ms/step\n",
      "Epoch 16/150\n",
      "75/75 - 4s - loss: 1.2197 - accuracy: 0.2719 - val_loss: 1.8685 - val_accuracy: 0.1937 - 4s/epoch - 55ms/step\n",
      "Epoch 17/150\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "75/75 - 5s - loss: 1.1883 - accuracy: 0.2815 - val_loss: 1.8795 - val_accuracy: 0.1952 - 5s/epoch - 61ms/step\n",
      "Epoch 17: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e91881fb50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data,validation_split=0.2, epochs=150,verbose=2,callbacks=[earlyStopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4b5ad2e-4855-4d27-ab41-66c5af92897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02e3b1eb-1293-4758-b14b-9ed84f3e319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    for word in words:\n",
    "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "    return tf.keras.preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1d5ccce-9483-4d2b-ba3f-f57662be0c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.78382799e-01, 2.84035038e-02, 2.84499303e-02, ...,\n",
       "         2.62624735e-06, 2.50836661e-06, 2.68936310e-06],\n",
       "        [2.64580101e-01, 3.90688330e-02, 3.23100984e-02, ...,\n",
       "         1.84343344e-06, 1.69792975e-06, 1.70128646e-06],\n",
       "        [8.17695409e-02, 2.10882686e-02, 1.59607586e-02, ...,\n",
       "         1.10525334e-05, 1.05808858e-05, 1.01583955e-05],\n",
       "        [3.15135241e-01, 4.20886911e-02, 2.93629933e-02, ...,\n",
       "         1.66654024e-06, 1.53514850e-06, 1.48302649e-06],\n",
       "        [4.67917353e-01, 4.68271561e-02, 3.15175317e-02, ...,\n",
       "         5.31806336e-07, 4.86323586e-07, 4.74760867e-07],\n",
       "        [2.70807028e-01, 3.91846485e-02, 2.71630455e-02, ...,\n",
       "         2.49449454e-06, 2.35553648e-06, 2.30308251e-06]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand=np.random.randint(0,high=df['cleaned_Q'].shape[0])\n",
    "tokenized_questions = tokenizer.texts_to_sequences([clean_text(df['Question'][rand])])\n",
    "maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n",
    "padded_questions = tf.keras.preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen_questions , padding='post' )\n",
    "encoder_input_data = np.array( padded_questions )\n",
    "print(encoder_input_data.shape)\n",
    "tokenized_answers = tokenizer.texts_to_sequences( [clean_text(df['Question'][rand])] )\n",
    "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
    "padded_answers = tf.keras.preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "decoder_input_data = np.array( padded_answers )\n",
    "\n",
    "model.predict([encoder_input_data,decoder_input_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e2ce6-4eeb-44b9-862b-247e5d088768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
