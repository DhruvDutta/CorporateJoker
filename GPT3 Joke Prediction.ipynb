{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import uuid\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a helper function for easy input and access to openai's API\n",
    "https://github.com/shreyashankar/gpt3-sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_openai_key(key):\n",
    "    openai.api_key = key\n",
    "    \n",
    "class Example:\n",
    "    def __init__(self, inp, out):\n",
    "        self.input = inp\n",
    "        self.output = out\n",
    "        self.id = uuid.uuid4().hex\n",
    "\n",
    "    def get_input(self):\n",
    "        return self.input\n",
    "\n",
    "    def get_output(self):\n",
    "        return self.output\n",
    "\n",
    "    def get_id(self):\n",
    "        return self.id\n",
    "\n",
    "    def as_dict(self):\n",
    "        return {\n",
    "            \"input\": self.get_input(),\n",
    "            \"output\": self.get_output(),\n",
    "            \"id\": self.get_id(),\n",
    "        }\n",
    "\n",
    "\n",
    "class GPT:\n",
    "    def __init__(self,\n",
    "                 engine='davinci',\n",
    "                 temperature=0.5,\n",
    "                 max_tokens=100,\n",
    "                 input_prefix=\"input: \",\n",
    "                 input_suffix=\"\\n\",\n",
    "                 output_prefix=\"\",\n",
    "                 output_suffix=\"\",\n",
    "                 append_output_prefix_to_query=False):\n",
    "        self.examples = {}\n",
    "        self.engine = engine\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.input_prefix = input_prefix\n",
    "        self.input_suffix = input_suffix\n",
    "        self.output_prefix = output_prefix\n",
    "        self.output_suffix = output_suffix\n",
    "        self.append_output_prefix_to_query = append_output_prefix_to_query\n",
    "        self.stop = (output_suffix + input_prefix).strip()\n",
    "\n",
    "    def add_example(self, ex):\n",
    "        assert isinstance(ex, Example), \"Please create an Example object.\"\n",
    "        self.examples[ex.get_id()] = ex\n",
    "\n",
    "    def delete_example(self, id):\n",
    "        if id in self.examples:\n",
    "            del self.examples[id]\n",
    "\n",
    "    def get_example(self, id):\n",
    "        return self.examples.get(id, None)\n",
    "\n",
    "    def get_all_examples(self):\n",
    "        return {k: v.as_dict() for k, v in self.examples.items()}\n",
    "\n",
    "    def get_prime_text(self):\n",
    "        return \"\".join(\n",
    "            [self.format_example(ex) for ex in self.examples.values()])\n",
    "\n",
    "    def get_engine(self):\n",
    "        return self.engine\n",
    "\n",
    "    def get_temperature(self):\n",
    "        return self.temperature\n",
    "\n",
    "    def get_max_tokens(self):\n",
    "        return self.max_tokens\n",
    "\n",
    "    def craft_query(self, prompt):\n",
    "        q = self.get_prime_text(\n",
    "        ) + self.input_prefix + prompt + self.input_suffix\n",
    "        if self.append_output_prefix_to_query:\n",
    "            q = q + self.output_prefix\n",
    "        return q\n",
    "\n",
    "    def submit_request(self, prompt):\n",
    "        response = openai.Completion.create(engine=self.get_engine(),\n",
    "                                            prompt=self.craft_query(prompt),\n",
    "                                            max_tokens=self.get_max_tokens(),\n",
    "                                            temperature=self.get_temperature(),\n",
    "                                            top_p=1,\n",
    "                                            n=1,\n",
    "                                            stream=False,\n",
    "                                            stop=self.stop)\n",
    "        return response\n",
    "\n",
    "    def get_top_reply(self, prompt):\n",
    "        response = self.submit_request(prompt)\n",
    "        return response['choices'][0]['text']\n",
    "\n",
    "    def format_example(self, ex):\n",
    "        return self.input_prefix + ex.get_input(\n",
    "        ) + self.input_suffix + self.output_prefix + ex.get_output(\n",
    "        ) + self.output_suffix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input your openai secret key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input your open ai service key: ···················································\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "city = getpass.getpass('Input your open ai service key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So lets now move onto producing jokes\n",
    "https://www.kaggle.com/datasets/jiriroz/qa-jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3 = GPT(engine=\"davinci\", temperature=0.5, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Did you hear about the Native American man tha...</td>\n",
       "      <td>He nearly drown in his own tea pee.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What's the best anti diarrheal prescription?</td>\n",
       "      <td>Mycheexarphlexin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>What do you call a person who is outside a doo...</td>\n",
       "      <td>Matt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Which Star Trek character is a member of the m...</td>\n",
       "      <td>Jean-Luc Pickacard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What's the difference between a bullet and a h...</td>\n",
       "      <td>A bullet doesn't miss Harambe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           Question  \\\n",
       "0   1  Did you hear about the Native American man tha...   \n",
       "1   2       What's the best anti diarrheal prescription?   \n",
       "2   3  What do you call a person who is outside a doo...   \n",
       "3   4  Which Star Trek character is a member of the m...   \n",
       "4   5  What's the difference between a bullet and a h...   \n",
       "\n",
       "                                Answer  \n",
       "0  He nearly drown in his own tea pee.  \n",
       "1                     Mycheexarphlexin  \n",
       "2                                 Matt  \n",
       "3                   Jean-Luc Pickacard  \n",
       "4        A bullet doesn't miss Harambe  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes = pd.read_csv('jokes.csv')\n",
    "jokes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38269"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What happens if you violate Reddit's content policy?\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = np.random.randint(0,high=len(jokes),size=1)\n",
    "jokes['Question'][rand[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you get when you put a flight stick in an egg?  :  A yoke. \n",
      "What's the difference between the Mafia and the Government?  :  Only one of them is organized.\n",
      "Why can't you feel photons?  :  Because they are light. \n",
      "What do old cars and dead chickens have in common?  :  You'll usually get more money for them if you sell them for parts \n",
      "What's Donald's true political party?  :  Whig\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    rand = np.random.randint(0,high=len(jokes),size=1)\n",
    "    ques = jokes['Question'][rand[0]]\n",
    "    ans = jokes['Answer'][rand[0]]\n",
    "    print(ques , \" : \", ans)\n",
    "    gpt3.add_example(Example(ques,ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get individual examples like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3.get_example(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They want to. '"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Why do most married men die before their wives?\"\n",
    "output = gpt3.submit_request(prompt)\n",
    "output.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not a dog, I'm a cat. \""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"what did the dog say to a cat?\"\n",
    "output = gpt3.submit_request(prompt)\n",
    "output.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(gpt3, './jokePredictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They used the pirate-net. '"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"jokePredictor\")\n",
    "output = model.submit_request(\"How did pirates communicate before the internet?\")\n",
    "output.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jokeResponder(txt):\n",
    "    model = torch.load(\"jokePredictor\")\n",
    "    output = model.submit_request(txt)\n",
    "    return output.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomJoke():\n",
    "    rand = np.random.randint(0,high=len(jokes),size=1)\n",
    "    ques = jokes['Question'][rand[0]]\n",
    "    model = torch.load(\"jokePredictor\")\n",
    "    output = model.submit_request(ques)\n",
    "    return ques+\" : \"+output.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What type of lights were on Noah's Ark? :  Flood lights. \""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomJoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I\\'m a little Brussels sprout.\" '"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokeResponder('What did the vegetable say to the dj?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
